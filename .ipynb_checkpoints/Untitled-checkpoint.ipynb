{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a947488d-8396-408f-9453-04d0ccbc1029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: C:\\AIDC\\travel\\temp_models_betatest\n",
      "ğŸ”¹ TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# === ì„¤ì • ===\n",
    "# í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
    "BASE_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"temp_models_betatest\")\n",
    "\n",
    "# ì„ì‹œ ëª¨ë¸ ì €ì¥ í´ë” ìƒì„±\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print(f\"ğŸ“‚ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {MODEL_DIR}\")\n",
    "print(f\"ğŸ”¹ TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# --- ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„° (ë”ë¯¸ìš©) ---\n",
    "VOCAB_SIZE = 1000  # ë‹¨ì–´ ì‚¬ì „ í¬ê¸°\n",
    "MAX_LEN = 50       # ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´\n",
    "EMBEDDING_DIM = 64 # ì„ë² ë”© ì°¨ì›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b016cc4a-b39d-48d9-aa0f-07d85e1ec048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\AIDC\\travel\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1189d04-64d9-477b-bde8-12b4ee725d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.1-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from torch) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\aidc\\travel\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\aidc\\travel\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\aidc\\travel\\.venv\\lib\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Using cached torch-2.9.1-cp310-cp310-win_amd64.whl (111.0 MB)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached sentencepiece-0.2.1-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading regex-2025.11.3-cp310-cp310-win_amd64.whl (277 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, sentencepiece, safetensors, regex, networkx, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.20.0 fsspec-2025.12.0 huggingface-hub-0.36.0 mpmath-1.3.0 networkx-3.4.2 regex-2025.11.3 safetensors-0.7.0 sentencepiece-0.2.1 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b6c698-9a7b-495e-91ca-62dffadd2d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AIDC\\travel\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: C:\\AIDC\\travel\\advanced_models_sota\n",
      "ğŸ”¹ Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    ElectraConfig, ElectraForTokenClassification, ElectraForSequenceClassification, # M1, M2ìš©\n",
    "    BartConfig, BartForConditionalGeneration, # M3ìš©\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "# === ì„¤ì • ===\n",
    "BASE_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"advanced_models_sota\")\n",
    "\n",
    "# í´ë” ìƒì„±\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print(f\"ğŸ“‚ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {MODEL_DIR}\")\n",
    "\n",
    "# CPU/GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ”¹ Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f4c52a-ee17-4cf6-b44c-7fc462f0ca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [M1] KoELECTRA (NER) ìƒì„± ë° ì €ì¥ ---\n",
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: C:\\AIDC\\travel\\advanced_models_sota\\koelectra_ner\n",
      "\n",
      "--- [M1] ë¡œë“œ ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸ ---\n",
      "   ã„´ ì¶œë ¥ í˜•íƒœ: torch.Size([1, 50, 5])\n",
      "   ã„´ ì •ìƒ ì‘ë™ í™•ì¸.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- [M1] KoELECTRA (NER) ìƒì„± ë° ì €ì¥ ---\")\n",
    "\n",
    "# 1. ì„¤ì • (Config) ìƒì„± - ì‹¤ì œ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ëŒ€ì‹  êµ¬ì¡°ë§Œ ê°€ì ¸ì˜´ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)\n",
    "# ì‹¤ì œ ì‚¬ìš©ì‹œëŠ” 'monologg/koelectra-base-v3-discriminator' ë“±ì„ ì‚¬ìš©\n",
    "config_m1 = ElectraConfig(\n",
    "    vocab_size=30000,\n",
    "    hidden_size=64, # í…ŒìŠ¤íŠ¸ìš©ì´ë¼ ì‘ê²Œ ì„¤ì • (ì›ë˜ëŠ” 768)\n",
    "    num_hidden_layers=2, # ë ˆì´ì–´ ìˆ˜ë„ ì¶•ì†Œ\n",
    "    num_labels=5, # íƒœê·¸ ê°œìˆ˜ (B-Hotel, I-Price ë“±)\n",
    "    max_position_embeddings=128\n",
    ")\n",
    "\n",
    "# 2. ëª¨ë¸ ì´ˆê¸°í™” (Random Weights)\n",
    "model_m1 = ElectraForTokenClassification(config_m1).to(device)\n",
    "\n",
    "# 3. ì €ì¥ (Hugging Face í‘œì¤€ ë°©ì‹)\n",
    "m1_path = os.path.join(MODEL_DIR, \"koelectra_ner\")\n",
    "model_m1.save_pretrained(m1_path)\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {m1_path}\")\n",
    "\n",
    "# --- Load & Test ---\n",
    "print(\"\\n--- [M1] ë¡œë“œ ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸ ---\")\n",
    "loaded_m1 = ElectraForTokenClassification.from_pretrained(m1_path).to(device)\n",
    "loaded_m1.eval()\n",
    "\n",
    "# ë”ë¯¸ ì…ë ¥ (Batch: 1, Length: 50)\n",
    "dummy_input_ids = torch.randint(0, 30000, (1, 50)).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = loaded_m1(dummy_input_ids)\n",
    "    logits = outputs.logits # (1, 50, 5)\n",
    "\n",
    "print(f\"   ã„´ ì¶œë ¥ í˜•íƒœ: {logits.shape}\")\n",
    "print(\"   ã„´ ì •ìƒ ì‘ë™ í™•ì¸.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cac999c-5638-4aa5-b2dd-45b777bed1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [M2] KoELECTRA Small (Sentiment) ìƒì„± ë° ì €ì¥ ---\n",
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: C:\\AIDC\\travel\\advanced_models_sota\\koelectra_sentiment\n",
      "\n",
      "--- [M2] ë¡œë“œ ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸ ---\n",
      "   ã„´ ì˜ˆì¸¡ í™•ë¥  ë¶„í¬: [0.33100206 0.3322725  0.33672547]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- [M2] KoELECTRA Small (Sentiment) ìƒì„± ë° ì €ì¥ ---\")\n",
    "\n",
    "# 1. ì„¤ì • (3-Class: ê¸ì •/ë¶€ì •/ë³´ë¥˜)\n",
    "config_m2 = ElectraConfig(\n",
    "    vocab_size=30000,\n",
    "    hidden_size=64,\n",
    "    num_hidden_layers=2,\n",
    "    num_labels=3, # 3ì¤‘ ë¶„ë¥˜\n",
    "    max_position_embeddings=128\n",
    ")\n",
    "\n",
    "# 2. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model_m2 = ElectraForSequenceClassification(config_m2).to(device)\n",
    "\n",
    "# 3. ì €ì¥\n",
    "m2_path = os.path.join(MODEL_DIR, \"koelectra_sentiment\")\n",
    "model_m2.save_pretrained(m2_path)\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {m2_path}\")\n",
    "\n",
    "# --- Load & Test ---\n",
    "print(\"\\n--- [M2] ë¡œë“œ ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸ ---\")\n",
    "loaded_m2 = ElectraForSequenceClassification.from_pretrained(m2_path).to(device)\n",
    "loaded_m2.eval()\n",
    "\n",
    "dummy_input_ids = torch.randint(0, 30000, (1, 50)).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = loaded_m2(dummy_input_ids)\n",
    "    probs = torch.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "print(f\"   ã„´ ì˜ˆì¸¡ í™•ë¥  ë¶„í¬: {probs[0].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b4918b-1571-42e4-9a60-118c77f93083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [M3] KoBART (Summarizer) ìƒì„± ë° ì €ì¥ ---\n",
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: C:\\AIDC\\travel\\advanced_models_sota\\kobart_summary\n",
      "\n",
      "--- [M3] ë¡œë“œ ë° ìƒì„± í…ŒìŠ¤íŠ¸ ---\n",
      "   ã„´ ìƒì„±ëœ ìš”ì•½ë¬¸ í† í° ID: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- [M3] KoBART (Summarizer) ìƒì„± ë° ì €ì¥ ---\")\n",
    "\n",
    "# 1. ì„¤ì • (Encoder-Decoder êµ¬ì¡°)\n",
    "config_m3 = BartConfig(\n",
    "    vocab_size=30000,\n",
    "    d_model=64,       # hidden size\n",
    "    encoder_layers=2,\n",
    "    decoder_layers=2,\n",
    "    max_position_embeddings=128\n",
    ")\n",
    "\n",
    "# 2. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model_m3 = BartForConditionalGeneration(config_m3).to(device)\n",
    "\n",
    "# 3. ì €ì¥\n",
    "m3_path = os.path.join(MODEL_DIR, \"kobart_summary\")\n",
    "model_m3.save_pretrained(m3_path)\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {m3_path}\")\n",
    "\n",
    "# --- Load & Test ---\n",
    "print(\"\\n--- [M3] ë¡œë“œ ë° ìƒì„± í…ŒìŠ¤íŠ¸ ---\")\n",
    "loaded_m3 = BartForConditionalGeneration.from_pretrained(m3_path).to(device)\n",
    "loaded_m3.eval()\n",
    "\n",
    "dummy_input_ids = torch.randint(0, 30000, (1, 100)).to(device) # ê¸´ ë¬¸ì¥ ì…ë ¥\n",
    "\n",
    "with torch.no_grad():\n",
    "    # generate() í•¨ìˆ˜ë¥¼ í†µí•´ ìš”ì•½ë¬¸ ìƒì„±\n",
    "    summary_ids = loaded_m3.generate(dummy_input_ids, max_length=20)\n",
    "\n",
    "print(f\"   ã„´ ìƒì„±ëœ ìš”ì•½ë¬¸ í† í° ID: {summary_ids.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c63200-0f98-4ff1-9e4c-c1c8ba443d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [M4] N-BEATS Style (Forecaster) ìƒì„± ë° ì €ì¥ ---\n",
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: C:\\AIDC\\travel\\advanced_models_sota\\nbeats_forecast.pth\n",
      "\n",
      "--- [M4] ë¡œë“œ ë° ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ---\n",
      "   ã„´ ì…ë ¥ ë°ì´í„°: torch.Size([1, 30])\n",
      "   ã„´ ì˜ˆì¸¡ê°’: 0.03153858706355095\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- [M4] N-BEATS Style (Forecaster) ìƒì„± ë° ì €ì¥ ---\")\n",
    "\n",
    "# 1. ê°„ë‹¨í•œ N-BEATS ìŠ¤íƒ€ì¼ ëª¨ë¸ ì •ì˜ (PyTorch)\n",
    "class SimpleNBeats(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=64):\n",
    "        super(SimpleNBeats, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim) # Trend ì˜ˆì¸¡\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (Batch, Time_Steps) - ì—¬ê¸°ì„  ë‹¨ìˆœí™”\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        return self.fc3(out)\n",
    "\n",
    "# 2. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "TIME_STEPS = 30 # ê³¼ê±° 30ì¼\n",
    "FORECAST_HORIZON = 1 # ë‹¤ìŒë‚  ì˜ˆì¸¡\n",
    "model_m4 = SimpleNBeats(input_dim=TIME_STEPS, output_dim=FORECAST_HORIZON).to(device)\n",
    "\n",
    "# 3. ì €ì¥ (PyTorch ë°©ì‹)\n",
    "m4_path = os.path.join(MODEL_DIR, \"nbeats_forecast.pth\")\n",
    "torch.save(model_m4.state_dict(), m4_path)\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {m4_path}\")\n",
    "\n",
    "# --- Load & Test ---\n",
    "print(\"\\n--- [M4] ë¡œë“œ ë° ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ---\")\n",
    "loaded_m4 = SimpleNBeats(input_dim=TIME_STEPS, output_dim=FORECAST_HORIZON).to(device)\n",
    "loaded_m4.load_state_dict(torch.load(m4_path))\n",
    "loaded_m4.eval()\n",
    "\n",
    "# ë”ë¯¸ ì…ë ¥ (Batch: 1, 30ì¼ì¹˜ ë°ì´í„°)\n",
    "dummy_input = torch.randn(1, TIME_STEPS).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = loaded_m4(dummy_input)\n",
    "\n",
    "print(f\"   ã„´ ì…ë ¥ ë°ì´í„°: {dummy_input.shape}\")\n",
    "print(f\"   ã„´ ì˜ˆì¸¡ê°’: {pred.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4397331-82cb-478e-973a-4149a1c45b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [Pre] Tokenizer ìƒì„± ---\n",
      "âœ… Tokenizer ì €ì¥ ì™„ë£Œ: C:\\AIDC\\travel\\advanced_models_sota\\tokenizer\n",
      "   ã„´ í† í°í™” ê²°ê³¼: ['ì—¬', '##í–‰', 'ê°€', '##ê³ ', 'ì‹¶', '##ì–´', '##ìš”']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- [Pre] Tokenizer ìƒì„± ---\")\n",
    "\n",
    "# ì‹¤ì œë¡œëŠ” 'monologg/koelectra...' ë“±ì„ ë‹¤ìš´ë¡œë“œ ë°›ì§€ë§Œ\n",
    "# ì—¬ê¸°ì„œëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì„ì‹œ í† í¬ë‚˜ì´ì € ì €ì¥ êµ¬ì¡°ë§Œ í‰ë‚´ëƒ…ë‹ˆë‹¤.\n",
    "# (ì¸í„°ë„· ì—°ê²°ì´ ìˆë‹¤ë©´ AutoTokenizer.from_pretrained('bert-base-multilingual-cased') ë“±ì„ ì‚¬ìš© ê¶Œì¥)\n",
    "\n",
    "try:\n",
    "    # ì¸í„°ë„·ì´ ì—°ê²°ë˜ì–´ ìˆë‹¤ë©´ ì‹¤ì œ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ í›„ ì €ì¥\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokenizer_path = os.path.join(MODEL_DIR, \"tokenizer\")\n",
    "    tokenizer.save_pretrained(tokenizer_path)\n",
    "    print(f\"âœ… Tokenizer ì €ì¥ ì™„ë£Œ: {tokenizer_path}\")\n",
    "    \n",
    "    # ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "    loaded_tok = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    tokens = loaded_tok.tokenize(\"ì—¬í–‰ ê°€ê³  ì‹¶ì–´ìš”\")\n",
    "    print(f\"   ã„´ í† í°í™” ê²°ê³¼: {tokens}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ ì¸í„°ë„· ì—°ê²°ì´ ì—†ê±°ë‚˜ ëª¨ë¸ IDê°€ ì˜ëª»ë˜ì–´ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨.\")\n",
    "    print(\"   ì‹¤ë¬´ì—ì„œëŠ” ì‚¬ë‚´ë§ ë°˜ì… ì ˆì°¨ë¥¼ í†µí•´ 'vocab.txt' ë“±ì„ í™•ë³´í•´ì•¼ í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f7df3-4a50-4efc-8963-2c8fb535a5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f95d8-7e73-455f-aaf7-11c3fe1fcd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e46d51-40e7-4765-a343-0f5e0790025a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63fb1e-fa30-4b04-a5a2-c46287ab302b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848393f7-3693-44d4-8798-7abcf701c6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7eb06-db29-4f70-af19-a810978d08e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a87ef-2a7d-4939-ac6b-095c4fba006c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dc679-7479-49c9-aba6-02876cde9cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a7263-5c38-4709-9631-8651199731f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e770a5-c14c-45e3-a52c-142d91ef427c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eed48a-42a7-49a7-a701-fb61d8e3e0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb792d2-f4d3-45bc-8fcd-104df86f7d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593db32-7fe9-4f6e-9ef4-6e33e4bb131d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd40677-2890-44e9-8b40-8890bd58e2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687923c3-8cad-408b-8726-c7f080f6d2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89e355-a705-470a-9339-2354eb396cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6a29b-f5d9-4efb-a543-b67a742ccd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65708a-179a-44b3-9a7a-4586935df686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd68a3f-83ec-460d-8eec-83711f0438be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42066afa-f9af-4cf4-a5b9-63f377b68567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97cef6c-2325-49ab-b419-bc4eeb95e903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19dc0cf-39ac-4905-9b6a-edd697e7f6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef206e-3b6b-429c-8ac4-4056ddc1dd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d423f4ae-30f2-494b-98cb-e005b888a5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1eb153-9fd8-4f0c-b64b-a4ad795009ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f59f0-68f2-4e73-92ab-0609dca1ea01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (travel)",
   "language": "python",
   "name": "travel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
